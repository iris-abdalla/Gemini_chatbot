{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXDCPN2dAlK5gMZqwpxMcd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iris-abdalla/Gemini_chatbot/blob/main/Primeiro_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver um passo a passo de como criar um chatbot utilizando a API do Gemini :"
      ],
      "metadata": {
        "id": "583YeZZGtFSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1º instale o SDK do Google"
      ],
      "metadata": {
        "id": "XQcY9qSDsYfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "glRbLeMlsmuY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importe os pacotes do google generative ai utilizando sua API"
      ],
      "metadata": {
        "id": "rgI24s1_v1O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "sDXS1b33vDe3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "qhsOLEywvXKG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos listar os modelos disponíveis\n",
        "\n",
        "Isso é importante para quando sair novas atualizações, você poder verificar se o seu código está estável e apontando para a última versão de teste\n",
        "\n"
      ],
      "metadata": {
        "id": "O0SQq0MbwKge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "FJJhF7VRvXHL",
        "outputId": "85e9e31a-f91b-4ccb-ebfc-516c42fe251c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos criar as configurações do seu chatbot a nível de código"
      ],
      "metadata": {
        "id": "QwPW5o7QzST8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_settings = {\n",
        "    'candidate_count': 1,\n",
        "    'temperature' : 0.5,\n",
        "}\n",
        " # na contagem de candidatos, colocamos 1 porque ele vai trazer apenas um candidato das opções como resposta, se colocar mais ele trará mais opções de resposta.\n",
        " # aqui colocamos a temperatuda em 0.5 porque os valores vão de 0 à 1, onde 0 o modelo fica \"engessado\" com o que você treina ele e 1 o modelo fica muito criativo\n"
      ],
      "metadata": {
        "id": "WiFCDy9ozRML"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações de segurança do meu chatbot"
      ],
      "metadata": {
        "id": "HzA8e0um1nWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    'Harassment' : 'block most',\n",
        "    'Hate' : 'block_most',\n",
        "    'Sexual' : 'block_most',\n",
        "    'Dangerous': 'block_most',\n",
        "}"
      ],
      "metadata": {
        "id": "uDdE8Fr01sG8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciando o modelo"
      ],
      "metadata": {
        "id": "EAu6BeO1wFR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro')\n",
        "generate_settings = generate_settings,\n",
        "safety_settings = safety_settings"
      ],
      "metadata": {
        "id": "7aq1bc4ZwOGa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste do modelo"
      ],
      "metadata": {
        "id": "lyECL6XMyXID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Você está vivo?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2sB_lxcQylnU",
        "outputId": "d217f131-5bf5-487e-cfbd-b740fba510a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Não sou um ser vivo. Sou Gemini, um modelo de linguagem de IA multimodal desenvolvido pelo Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legal, deu certo! Então vamos criar um chat para conversarmos melhor."
      ],
      "metadata": {
        "id": "1P1NbBSW1Yei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos dizer pro chat pra ele ter um histórico da nossa conversa, assim ele não perde o contexto do nosso diálogo."
      ],
      "metadata": {
        "id": "ID3tONwH2VlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "1qPQsFC01jVW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos criar um campo de input para enviar o que quisermos pro nosso chat."
      ],
      "metadata": {
        "id": "2FzWVeMd2hVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Digite uma pergunta \")\n",
        "\n",
        "while prompt != 'fim':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('Resposta: ', response.text, '\\n') # até aqui ele vai funcionar, mas ele vai sempre ficar esperando um fim, porque a requisição pro prompt está lá no começo, ele nunca vai ter um fim. então jogamos a chamada de input do promp no final para que ao final da resposta ele gere uma nova chamada para o prompt.\n",
        "  prompt = input(\"Digite uma pergunta \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "CK75Xk6H2ogF",
        "outputId": "49c34cad-a1af-48b4-e8c7-4afce0f9c67a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite uma pergunta Em que ano o homem pousou na lua?\n",
            "Resposta:  1969 \n",
            "\n",
            "Digite uma pergunta quantos homens pousaram na lua?\n",
            "Resposta:  12\n",
            "\n",
            "Os nomes dos 12 astronautas que pousaram na Lua são:\n",
            "\n",
            "* Neil Armstrong\n",
            "* Buzz Aldrin\n",
            "* Alan Bean\n",
            "* Alan Shepard\n",
            "* Edgar Mitchell\n",
            "* David Scott\n",
            "* James Irwin\n",
            "* John Young\n",
            "* Charles Duke\n",
            "* Eugene Cernan\n",
            "* Harrison Schmitt\n",
            "* Ronald Evans \n",
            "\n",
            "Digite uma pergunta fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "GrJ_OgoE9q7-",
        "outputId": "66f631a4-2813-4ad7-f9d6-055024b95fa1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Em que ano o homem pousou na lua?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: 1969"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Em que ano o homem pousou na lua?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: 1969"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: quantos homens pousaram na lua?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: 12\n> \n> Os nomes dos 12 astronautas que pousaram na Lua são:\n> \n> * Neil Armstrong\n> * Buzz Aldrin\n> * Alan Bean\n> * Alan Shepard\n> * Edgar Mitchell\n> * David Scott\n> * James Irwin\n> * John Young\n> * Charles Duke\n> * Eugene Cernan\n> * Harrison Schmitt\n> * Ronald Evans"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}